{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(1, os.path.dirname(os.path.realpath(__file__)) + '/../')\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from datagen.synthetic.single import sphere, swissroll\n",
    "from datagen.synthetic.multiple import intertwinedswissrolls, wellseparatedspheres, concentricspheres\n",
    "\n",
    "from expC.expC_utils.common import *\n",
    "from expC.expC_utils import plot_ittwswrolls\n",
    "\n",
    "MFLD_TYPES = {\n",
    "    \"single-sphere\": sphere.RandomSphere,\n",
    "    \"single-swissroll\": swissroll.RandomSwissRoll,\n",
    "    \"ittw-swissrolls\": intertwinedswissrolls.IntertwinedSwissRolls,\n",
    "    \"inf-ittw-swissrolls\": intertwinedswissrolls.IntertwinedSwissRolls,\n",
    "    \"inf-ws-spheres\": wellseparatedspheres.WellSeparatedSpheres,\n",
    "    \"inf-conc-spheres\": concentricspheres.ConcentricSpheres\n",
    "}\n",
    "\n",
    "MFLD_VIZ_BY_TYPE = {\n",
    "    \"ittw-swissrolls\": plot_ittwswrolls,\n",
    "    \"inf-ittw-swissrolls\": plot_ittwswrolls,\n",
    "    \"inf-ws-spheres\": plot_ittwswrolls,\n",
    "    \"inf-conc-spheres\": plot_ittwswrolls\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'sans-serif',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use = (\n",
    "#     ('red', \"pink\"),\n",
    "#     ('blue', \"lightsteelblue\"),\n",
    "#     ('gold', \"yellow\")\n",
    "# )\n",
    "\n",
    "use = (\n",
    "    ('darkred', \"coral\"),\n",
    "    ('navy', \"cornflowerblue\"),\n",
    "    ('gold', \"palegreen\")\n",
    ")\n",
    "\n",
    "cm_1_dl = LinearSegmentedColormap.from_list('use1dl', [u[0] for u in use[:-1]], N=len(use[:-1]))\n",
    "cm_2_dl = LinearSegmentedColormap.from_list('use2dl', [u[1] for u in use], N=len(use))\n",
    "\n",
    "cm_1_sc = LinearSegmentedColormap.from_list('use1sc', [u[0] for u in use[:-1]], N=len(use[:-1]))\n",
    "cm_2_sc = LinearSegmentedColormap.from_list('use2sc', [u[1] for u in use[:-1]], N=len(use[:-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nplane_samples_for_kmfld_2(k_dim_samples, dataset, n=3, h=800):\n",
    "    \"\"\"\n",
    "    returns samples from n-dim plane containing the manifold\n",
    "\n",
    "    :param k_dim_samples: k-dim embeddings of the points. assume k=2\n",
    "    :type k_dim_samples: torch.Tensor\n",
    "    :param dataset: dataset object to get necessary transforms\n",
    "    :type dataset: torch.util.data.Dataset\n",
    "    :param n: the dimension of the space in which the plane will be\n",
    "    :type n: int\n",
    "    :param num_samples: number of samples to generate\n",
    "    :type num_samples:: int\n",
    "    \"\"\"\n",
    "    k = k_dim_samples.shape[1]\n",
    "    if type(k_dim_samples) == torch.Tensor:\n",
    "        k_dim_samples = k_dim_samples.numpy()\n",
    "    \n",
    "    low = (1 - np.sign(np.min(k_dim_samples)) * 0.1) * np.min(k_dim_samples) \n",
    "    high = (1 + np.sign(np.max(k_dim_samples)) * 0.1) * np.max(k_dim_samples)\n",
    "    x_min = low\n",
    "    y_min = low\n",
    "    x_max = high\n",
    "    y_max = high\n",
    "    if isinstance(dataset, concentricspheres.ConcentricSpheres):\n",
    "        x_min, x_max = np.min(k_dim_samples[:, 0]) * (1 - np.sign(np.min(k_dim_samples[:, 0])) * 0.1), np.max(k_dim_samples[:, 0]) * (1 + np.sign(np.max(k_dim_samples[:, 0])) * 0.1)\n",
    "        y_min, y_max = np.min(k_dim_samples[:, 1]) * (1 - np.sign(np.min(k_dim_samples[:, 1])) * 0.1), np.max(k_dim_samples[:, 1]) * (1 + np.sign(np.max(k_dim_samples[:, 1])) * 0.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max - x_min) / h),\\\n",
    "                      np.arange(y_min, y_max, (y_max - y_min) / h))\n",
    "    print(xx.shape, yy.shape)\n",
    "    gen_kd_grid = np.zeros((h * h, 2))\n",
    "    gen_kd_grid[:, 0] = xx.ravel()\n",
    "    gen_kd_grid[:, 1] = yy.ravel()\n",
    "                         \n",
    "    print(gen_kd_grid.shape)\n",
    "\n",
    "    num_samples = gen_kd_grid.shape[0]\n",
    "    gen_nd_grid = np.zeros((num_samples, n))\n",
    "\n",
    "    accessor = dataset\n",
    "    if isinstance(dataset, manifold.Manifold):\n",
    "        accessor = dataset.genattrs\n",
    "\n",
    "    gen_nd_grid[:, :k] = gen_kd_grid\n",
    "    gen_nd_grid = gen_nd_grid + accessor.translation\n",
    "    rotation = accessor.rotation\n",
    "    if len(accessor.rotation.shape) == 3 and accessor.rotation.shape[0] == 2:\n",
    "        rotation = accessor.rotation[0]\n",
    "    gen_nd_grid = np.dot(rotation, gen_nd_grid.T).T\n",
    "    gen_nd_grid = gen_nd_grid / accessor.norm_factor\n",
    "    gen_nd_grid = torch.from_numpy(gen_nd_grid).float()\n",
    "    gen_nd_grid = gen_nd_grid - accessor.anchor + accessor.fix_center\n",
    "\n",
    "    gen_kd_grid = torch.from_numpy(gen_kd_grid).float()\n",
    "    gen_nd_grid = gen_nd_grid.float()\n",
    "\n",
    "    return xx, yy, gen_kd_grid, gen_nd_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nplane_samples_for_kmfld_3(k_dim_samples, dataset, n=3, num_samples=50000):\n",
    "    \"\"\"\n",
    "    returns samples from n-dim plane containing the manifold\n",
    "\n",
    "    :param k_dim_samples: k-dim embeddings of the points\n",
    "    :type k_dim_samples: torch.Tensor\n",
    "    :param dataset: dataset object to get necessary transforms\n",
    "    :type dataset: torch.util.data.Dataset\n",
    "    :param n: the dimension of the space in which the plane will be\n",
    "    :type n: int\n",
    "    :param num_samples: number of samples to generate\n",
    "    :type num_samples:: int\n",
    "    \"\"\"\n",
    "    k = k_dim_samples.shape[1]\n",
    "    if type(k_dim_samples) == torch.Tensor:\n",
    "        k_dim_samples = k_dim_samples.numpy()\n",
    "\n",
    "    low = None\n",
    "    high = None\n",
    "    gen_kd_grid = None\n",
    "\n",
    "    if dataset.rotation.shape[0] == 2 or True:\n",
    "        print(\"hi\", dataset.rotation.shape)\n",
    "        x_min, x_max = np.min(k_dim_samples[:, 0]) * (1 - np.sign(np.min(k_dim_samples[:, 0])) * 0.1) -2, np.max(k_dim_samples[:, 0]) * (1 + np.sign(np.max(k_dim_samples[:, 0])) * 0.1) + 20\n",
    "        y_min, y_max = np.min(k_dim_samples[:, 1]) * (1 - np.sign(np.min(k_dim_samples[:, 1])) * 0.1) -2, np.max(k_dim_samples[:, 1]) * (1 + np.sign(np.max(k_dim_samples[:, 1])) * 0.1) + 20\n",
    "        low = np.array([x_min, y_min])\n",
    "        high = np.array([x_max, y_max])\n",
    "        gen_kd_grid = np.random.uniform(low, high, size=(num_samples, k))\n",
    "    else:\n",
    "        low = (1 - np.sign(np.min(k_dim_samples)) * 0.1) * np.min(k_dim_samples) \n",
    "        high = (1 + np.sign(np.max(k_dim_samples)) * 0.1) * np.max(k_dim_samples)\n",
    "\n",
    "        gen_kd_grid = np.random.uniform(low, high, size=(num_samples, k))\n",
    "\n",
    "    gen_nd_grid = np.zeros((num_samples, n))\n",
    "\n",
    "    accessor = dataset\n",
    "    if isinstance(dataset, manifold.Manifold):\n",
    "        accessor = dataset.genattrs\n",
    "\n",
    "    gen_nd_grid[:, :k] = gen_kd_grid\n",
    "    gen_nd_grid = gen_nd_grid + accessor.translation\n",
    "    rotation = accessor.rotation\n",
    "    if len(accessor.rotation.shape) == 3 and accessor.rotation.shape[0] == 2:\n",
    "        rotation = accessor.rotation[0]\n",
    "    gen_nd_grid = np.dot(rotation, gen_nd_grid.T).T\n",
    "    gen_nd_grid = gen_nd_grid / accessor.norm_factor\n",
    "    gen_nd_grid = torch.from_numpy(gen_nd_grid).float()\n",
    "    gen_nd_grid = gen_nd_grid - accessor.anchor + accessor.fix_center\n",
    "\n",
    "    gen_kd_grid = torch.from_numpy(gen_kd_grid).float()\n",
    "    gen_nd_grid = gen_nd_grid.float()\n",
    "\n",
    "    return gen_kd_grid, gen_nd_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots_2(model, dataset, dump_dir, task=\"regression\",\\\n",
    "     batch_size=8192, num_workers=8, cuda=1, plot_type=\"contour\", thresh=None, h=250, num_samples=50000):\n",
    "\n",
    "    # intertwined swiss rolls are planar swiss rolls\n",
    "    # so we will proceed as such\n",
    "    n = 0\n",
    "    k = 0\n",
    "    if isinstance(dataset, manifold.Manifold):\n",
    "        n = dataset.genattrs.n\n",
    "        k = dataset.genattrs.k\n",
    "        if thresh is None:\n",
    "            thresh = dataset.genattrs.D / dataset.genattrs.norm_factor\n",
    "    else:\n",
    "        n = dataset.n\n",
    "        k = dataset.k\n",
    "        if thresh is None:\n",
    "            thresh = dataset.S1.genattrs.D / dataset.norm_factor\n",
    "\n",
    "    points_k = get_coplanar_kdim_samples(dataset)\n",
    "    points_k_classes = dataset.class_labels[dataset.class_labels != 2]\n",
    "    \n",
    "    xx = 1\n",
    "    yy = None\n",
    "    gen_kd_grid = None\n",
    "    gen_nd_grid = None\n",
    "    dummy_labels = None\n",
    "    \n",
    "    num_classes = model.output_size\n",
    "    \n",
    "    if debug:\n",
    "    \n",
    "        gen_kd_grid = torch.load(\"{}_gen_kd_grid.pth\".format(task))\n",
    "        gen_nd_grid = torch.load(\"{}_gen_nd_grid.pth\".format(task))\n",
    "\n",
    "    if not debug:\n",
    "        if plot_type == \"contour\":\n",
    "            xx, yy, gen_kd_grid, gen_nd_grid = get_nplane_samples_for_kmfld_2(points_k, dataset, n, h)\n",
    "            dummy_labels = torch.from_numpy(np.zeros((h * h, num_classes))).float()\n",
    "        elif plot_type == \"sct\":\n",
    "            gen_kd_grid, gen_nd_grid = get_nplane_samples_for_kmfld_3(points_k, dataset, n, num_samples)\n",
    "            dummy_labels = torch.from_numpy(np.zeros((num_samples, num_classes))).float()\n",
    "    \n",
    "    \n",
    "        torch.save(gen_kd_grid, \"{}_gen_kd_grid.pth\".format(task))\n",
    "        torch.save(gen_nd_grid, \"{}_gen_nd_grid.pth\".format(task))\n",
    "    \n",
    "    if debug:\n",
    "        if plot_type == \"contour\":\n",
    "            dummy_labels = torch.from_numpy(np.zeros((h * h, num_classes))).float()\n",
    "        else:\n",
    "            dummy_labels = torch.from_numpy(np.zeros((num_samples, num_classes))).float()\n",
    "\n",
    "    if task == \"clf\":\n",
    "        dummy_labels = dummy_labels[:, 0].long()\n",
    "\n",
    "    gen_nd_dataset = TensorDataset(gen_nd_grid, dummy_labels)\n",
    "\n",
    "    gen_nd = DataLoader(dataset=gen_nd_dataset, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    device = torch.device(\"cuda:{}\".format(cuda) if torch.cuda.is_available() and cuda is not None else \"cpu\")\n",
    "    \n",
    "    if not debug:\n",
    "        _, _, _, gen_nd_logits = lmd.test(model, gen_nd, device, task=task, debug=False)\n",
    "        print(\"inference done\")\n",
    "        torch.save(gen_nd_logits, \"{}_gen_nd_logits.pth\".format(task))\n",
    "    \n",
    "    \n",
    "    gen_nd_logits = torch.load(\"{}_gen_nd_logits.pth\".format(task))\n",
    "    \n",
    "    gen_pred_classes = None\n",
    "    if task == \"clf\":\n",
    "        gen_pred_classes = torch.max(gen_nd_logits, axis=1)[1]\n",
    "    elif task == \"regression\":\n",
    "        gen_pred_classes = torch.min(gen_nd_logits, axis=1)[1]\n",
    "    \n",
    "    \n",
    "    return xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir\n",
    "\n",
    "\n",
    "\n",
    "def plot_decision_regions_2(xx, yy, h, gen_kd_grid, points_k, points_k_classes,\\\n",
    "     gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir, ax, plot_type=\"contour\"):\n",
    "\n",
    "\n",
    "\n",
    "    plotdir = \"./\"\n",
    "\n",
    "    THRESH = thresh\n",
    "    OFF_MFLD_LABEL = torch.max(gen_pred_classes) + 1\n",
    "\n",
    "    k = points_k.shape[1]\n",
    "    n = gen_nd_grid.shape[1]\n",
    "    if k not in [2, 3]:\n",
    "        raise RuntimeError(\"decision region visualization not possible\")\n",
    "\n",
    "    if task == \"regression\": gen_pred_classes[torch.min(gen_nd_logits, axis=1)[0] >= THRESH] = OFF_MFLD_LABEL\n",
    "    col = [\"red\", \"blue\", \"yellow\"]\n",
    "    \n",
    "    if len(np.unique(gen_pred_classes)) > 2:\n",
    "        print(np.unique(gen_pred_classes))\n",
    "        cm_1 = cm_1_dl\n",
    "        cm_2 = cm_2_dl\n",
    "    else:\n",
    "        cm_1 = cm_1_sc\n",
    "        cm_2 = cm_2_sc\n",
    "    \n",
    "    if k == 2:\n",
    "\n",
    "        if plot_type == \"contour\":\n",
    "            ax.contourf(xx, yy, gen_pred_classes.reshape(xx.shape), cmap=cm_2, alpha=0.8)\n",
    "\n",
    "\n",
    "            ax.scatter(gen_kd_grid[:, 0], gen_kd_grid[:, 1], c=gen_pred_classes, cmap=cm_2, s=0.01)\n",
    "            ax.scatter(points_k[:, 0], points_k[:, 1], c=points_k_classes, cmap=cm_1, s=0.1)\n",
    "        else:\n",
    "            add_to_idx = 0\n",
    "            if isinstance(dataset, concentricspheres.ConcentricSpheres):\n",
    "                add_to_idx = -1\n",
    "            ax.scatter(gen_kd_grid[:, 0 + add_to_idx], gen_kd_grid[:, 1 + add_to_idx], c=gen_pred_classes, cmap=cm_2, s=0.1)\n",
    "            ax.scatter(points_k[:, 0 + add_to_idx], points_k[:, 1 + add_to_idx], c=points_k_classes, cmap=cm_1, s=0.01)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_heatmap(xx, yy, h, gen_kd_grid, points_k, points_k_classes,\\\n",
    "     gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir, axs, plot_type=\"contour\"):\n",
    "\n",
    "    if task == \"clf\":\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        gen_nd_logits = softmax(gen_nd_logits)\n",
    "\n",
    "    plotdir = \"./\"\n",
    "\n",
    "    THRESH = thresh\n",
    "    OFF_MFLD_LABEL = torch.max(gen_pred_classes) + 1\n",
    "\n",
    "    k = points_k.shape[1]\n",
    "    n = gen_nd_grid.shape[1]\n",
    "    if k not in [2, 3]:\n",
    "        raise RuntimeError(\"decision region visualization not possible\")\n",
    "\n",
    "    if task == \"regression\": gen_pred_classes[torch.min(gen_nd_logits, axis=1)[0] >= THRESH] = OFF_MFLD_LABEL\n",
    "    col = [\"red\", \"blue\", \"yellow\"]\n",
    "    \n",
    "    if len(np.unique(gen_pred_classes)) > 2:\n",
    "        print(np.unique(gen_pred_classes))\n",
    "        cm_1 = cm_1_dl\n",
    "        cm_2 = cm_2_dl\n",
    "    else:\n",
    "        cm_1 = cm_1_sc\n",
    "        cm_2 = cm_2_sc\n",
    "    \n",
    "    if k == 2:\n",
    "\n",
    "        ax = axs\n",
    "        if plot_type == \"contour\":\n",
    "            ax.contourf(xx, yy, gen_nd_logits[:, i].reshape(xx.shape), cmap=cm_2, alpha=0.8)\n",
    "\n",
    "\n",
    "            ax.scatter(gen_kd_grid[:, 0], gen_kd_grid[:, 1], c=gen_nd_logits[:, i], cmap=\"hot\", s=0.05)\n",
    "            ax.scatter(points_k[:, 0][points_k_classes == i], points_k[:, 1][points_k_classes == i], c=[\"orange\", \"cyan\"], s=0.1)\n",
    "        else:\n",
    "            limit=1.1\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            add_to_idx = 0\n",
    "            if isinstance(dataset, concentricspheres.ConcentricSpheres):\n",
    "                add_to_idx = -1\n",
    "            sc = ax.scatter(gen_kd_grid[:, 0 + add_to_idx], gen_kd_grid[:, 1 + add_to_idx], c=torch.max(softmax(gen_nd_logits), dim=1)[0], cmap=\"autumn\", s=0.1)\n",
    "            ax.scatter(points_k[:, 0 + add_to_idx], points_k[:, 1 + add_to_idx], c=points_k_classes, cmap=cm_1, s=0.01)\n",
    "\n",
    "    \n",
    "    return sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis_2(dl_dump_dir, stdclf_dump_dir, on=\"test\", h=800, thresh=None, plot_type=\"contour\", num_samples=50000, plot_name=\"test\"):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if on not in [\"train\", \"test\", \"val\"]:\n",
    "        raise RuntimeError(\"`on` can only be one of 'train', 'test', 'val'\")\n",
    "\n",
    "    config_dict = load_config(dl_dump_dir)\n",
    "    task = config_dict[\"task\"]\n",
    "    model = load_model(dl_dump_dir)\n",
    "    data_dir = os.path.join(dl_dump_dir, \"../data\")\n",
    "    data_mfld_type = config_dict[\"data\"][\"mtype\"]\n",
    "\n",
    "#     train_set, val_set, test_set = MFLD_TYPES[data_mfld_type].load_splits(data_dir)\n",
    "    \n",
    "    fig_size = (4, 4)\n",
    "    if data_mfld_type == \"inf-ws-spheres\":\n",
    "        fig_size = (13, 4)\n",
    "    fig1, ax_array_1 = plt.subplots(1, 1, figsize=fig_size)\n",
    "    \n",
    "    data_set = MFLD_TYPES[data_mfld_type]()\n",
    "    data_set.load_data(os.path.join(data_dir, on))\n",
    "    \n",
    "#     data_set = val_set if on == \"val\" else test_set\n",
    "\n",
    "    xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir = make_plots_2(model, data_set, dl_dump_dir, task, h=h, plot_type=plot_type, num_samples=num_samples, thresh=thresh)\n",
    "\n",
    "    plot_decision_regions_2(xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid,\\\n",
    "                            gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir, ax_array_1, plot_type)\n",
    "    \n",
    "    # inset axes....\n",
    "    axins_1 = ax_array_1.inset_axes([0.5, 0.5, 0.47, 0.47])\n",
    "    plot_decision_regions_2(xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid,\\\n",
    "                            gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir, axins_1, plot_type)\n",
    "    # sub region of the original image\n",
    "    x1, x2, y1, y2 = -5, 5, -5, 5\n",
    "    axins_1.set_xlim(x1, x2)\n",
    "    axins_1.set_ylim(y1, y2)\n",
    "    axins_1.set_xticklabels([])\n",
    "    axins_1.set_yticklabels([])\n",
    "    ax_array_1.indicate_inset_zoom(axins_1, edgecolor=\"black\")\n",
    "    \n",
    "    fig2, ax_array_2 = plt.subplots(1, 1, figsize=(5, 4))\n",
    " \n",
    "    \n",
    "    dl_data_dir = data_dir\n",
    "    data_dir = os.path.join(dump_dir, \"../data\")\n",
    "    config_dict = load_config(stdclf_dump_dir)\n",
    "    task = config_dict[\"task\"]\n",
    "    model = load_model(stdclf_dump_dir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if data_dir != dl_data_dir:\n",
    "        data_mfld_type = config_dict[\"data\"][\"mtype\"]\n",
    "        data_set = MFLD_TYPES[data_mfld_type]()\n",
    "        data_set.load_data(os.path.join(data_dir, on))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, task, dump_dir = make_plots_2(model, data_set, stdclf_dump_dir, task, h=h, plot_type=plot_type, num_samples=num_samples, thresh=thresh)\n",
    "    print(xx is None)\n",
    "    # plot figure 1\n",
    "    \n",
    "\n",
    "        \n",
    "    sc = plot_distance_heatmap(xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, \"clf\", dump_dir, ax_array_2, plot_type)\n",
    "    # inset axes....\n",
    "    axins_2 = ax_array_2.inset_axes([0.5, 0.5, 0.47, 0.47])\n",
    "    plot_distance_heatmap(xx, yy, h, gen_kd_grid, points_k, points_k_classes, gen_nd_grid, gen_pred_classes, gen_nd_logits, dataset, thresh, \"clf\", dump_dir, axins_2, plot_type)\n",
    "    # sub region of the original image\n",
    "    x1, x2, y1, y2 = -5, 5, -5, 5\n",
    "    axins_2.set_xlim(x1, x2)\n",
    "    axins_2.set_ylim(y1, y2)\n",
    "    axins_2.set_xticklabels([])\n",
    "    axins_2.set_yticklabels([])\n",
    "    ax_array_2.indicate_inset_zoom(axins_2, edgecolor=\"black\")\n",
    "\n",
    "    \n",
    "    fig2.colorbar(sc, ax=ax_array_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig1.savefig('conf_{}_{}_1.png'.format(plot_name, plot_type), dpi=300)\n",
    "    fig1.savefig('conf_{}_{}_1.pdf'.format(plot_name, plot_type), dpi=300)\n",
    "    fig1.savefig('conf_{}_{}_1.svg'.format(plot_name, plot_type), dpi=300)\n",
    "    \n",
    "    \n",
    "    fig2.savefig('conf_{}_{}_2.png'.format(plot_name, plot_type), dpi=300)\n",
    "    fig2.savefig('conf_{}_{}_2.pdf'.format(plot_name, plot_type), dpi=300)\n",
    "    fig2.savefig('conf_{}_{}_2.svg'.format(plot_name, plot_type), dpi=300)\n",
    "    plt.show()\n",
    "    return gen_nd_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dump = \"PATH_TO_DIST_LEARNER_DUMP\"\n",
    "stdclf_dump = \"PATH_TO_STDCLF_DUMP\"\n",
    "plot_name = \"PLOT_NAME\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = run_analysis_2(dl_dump, stdclf_dump, \"val\", h=300, thresh=0.025, plot_type=\"sct\", plot_name=plot_name, num_samples=100000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
