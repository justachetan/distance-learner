{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/data/t-achetan/adv_geom/src/\")\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from expB.myNNs import MTMLPwithNormalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3231288802188655e-06, 6.248548922400812e-06, 990)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fn = \"/data/t-achetan_2/dumps/expC_dist_learner_for_adv_ex/rdm_concspheres_test/rdm_concspheres_k50n500_noninfdist_moreoffmfldv3_bs4096_highmn40_inferred_maxtdelta_5e-3/2/models/running_ckpt.pth\"\n",
    "fn = \"/data/t-achetan/dumps/expC_dist_learner_for_adv_ex/rdm_concspheres_test/rdm_concspheres_k50n500_noninfdist_moreoffmfldv3_bs4096_highmn40_inferred_maxtdelta_1e-3/3/models/running_ckpt_epoch_990.pth\"\n",
    "\n",
    "dump = torch.load(fn)\n",
    "dump[\"loss\"], dump[\"val_loss\"], dump[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MTMLPwithNormalisation(input_size=500, output_size=2, use_tanh=False, use_relu=False, weight_norm=False)\n",
    "model.load_state_dict(dump[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1.5e-5)\n",
    "optimizer.load_state_dict(dump[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.999999999999999e-07\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_lr = dump[\"scheduler_state_dict\"][\"_last_lr\"][0]\n",
    "scheduler_params = {\"warmup\": 10, \"cooldown\": 700}\n",
    "num_epochs = 1000\n",
    "# lr_sched_factor = lambda epoch: (epoch + 991) / (scheduler_params[\"warmup\"]) if (epoch + 991) <= scheduler_params[\"warmup\"] else (1 if (epoch + 991) > scheduler_params[\"warmup\"] and (epoch + 991) < scheduler_params[\"cooldown\"] else max(0, 1 + (1 / (scheduler_params[\"cooldown\"] - (num_epochs + 991))) * ((epoch + 991) - scheduler_params[\"cooldown\"])))\n",
    "lr_sched_factor = lambda epoch: epoch / (scheduler_params[\"warmup\"]) if epoch <= scheduler_params[\"warmup\"] else (1 if epoch > scheduler_params[\"warmup\"] and epoch < scheduler_params[\"cooldown\"] else max(0, 1 + ((1 / (scheduler_params[\"cooldown\"] - num_epochs)) * (epoch - scheduler_params[\"cooldown\"])) ))\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_sched_factor, last_epoch=990)\n",
    "scheduler.load_state_dict(dump[\"scheduler_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.999999999999999e-07]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before step: [4.999999999999999e-07]\n",
      "991 -0.0033333333333333335 0.029999999999999916 4.4999999999999876e-07\n",
      "after step: [4.4999999999999876e-07]\n",
      "before step: [4.4999999999999876e-07]\n",
      "992 -0.0033333333333333335 0.026666666666666616 3.9999999999999924e-07\n",
      "after step: [3.9999999999999924e-07]\n",
      "before step: [3.9999999999999924e-07]\n",
      "993 -0.0033333333333333335 0.023333333333333317 3.4999999999999977e-07\n",
      "after step: [3.4999999999999977e-07]\n",
      "before step: [3.4999999999999977e-07]\n",
      "994 -0.0033333333333333335 0.019999999999999907 2.999999999999986e-07\n",
      "after step: [2.999999999999986e-07]\n",
      "before step: [2.999999999999986e-07]\n",
      "995 -0.0033333333333333335 0.016666666666666607 2.4999999999999914e-07\n",
      "after step: [2.4999999999999914e-07]\n",
      "before step: [2.4999999999999914e-07]\n",
      "996 -0.0033333333333333335 0.013333333333333308 1.9999999999999962e-07\n",
      "after step: [1.9999999999999962e-07]\n",
      "before step: [1.9999999999999962e-07]\n",
      "997 -0.0033333333333333335 0.009999999999999898 1.4999999999999848e-07\n",
      "after step: [1.4999999999999848e-07]\n",
      "before step: [1.4999999999999848e-07]\n",
      "998 -0.0033333333333333335 0.006666666666666599 9.999999999999898e-08\n",
      "after step: [9.999999999999898e-08]\n",
      "before step: [9.999999999999898e-08]\n",
      "999 -0.0033333333333333335 0.0033333333333332993 4.999999999999949e-08\n",
      "after step: [4.999999999999949e-08]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs-991):\n",
    "    print(\"before step:\", scheduler.get_last_lr())\n",
    "    print(i + 991, 1 / (scheduler_params[\"cooldown\"] - num_epochs), lr_sched_factor(i + 991), lr_sched_factor(i + 991) * 1.5e-05)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(\"after step:\", scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.999999999999949e-08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.get_last_lr()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_lrs': [1.5e-05],\n",
       " 'last_epoch': 990,\n",
       " '_step_count': 991,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [4.999999999999999e-07],\n",
       " 'lr_lambdas': [None]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump[\"scheduler_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4999999999999952e-08"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.029999999999999916 * 4.999999999999999e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_lrs': [1.5e-05],\n",
       " 'last_epoch': 999,\n",
       " '_step_count': 1000,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [4.999999999999949e-08],\n",
       " 'lr_lambdas': [None]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
