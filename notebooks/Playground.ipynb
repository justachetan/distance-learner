{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utee import selector\n",
    "model_raw, ds_fetcher, is_imagenet = selector.select('resnet50')\n",
    "ds_val = ds_fetcher(batch_size=10, train=False, val=True)\n",
    "for idx, (data, target) in enumerate(ds_val):\n",
    "    data =  Variable(torch.FloatTensor(data)).cuda()\n",
    "    output = model_raw(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"/data/adv_geom/drg/\")\n",
    "from models.classifier import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets  drg  dumps  notebooks\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m[1802210728] [Warning] running without display\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from training.train_classifier import TrainClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n",
      "\u001b[94m[1802210728] -- TrainClassifier\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] train_images_file=/data/adv_geom/datasets/emnist/train_images.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] train_codes_file=/data/adv_geom/datasets/emnist/train_labels.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] test_images_file=/data/adv_geom/datasets/emnist/test_images.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] test_codes_file=/data/adv_geom/datasets/emnist/test_labels.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] state_file=/data/adv_geom/dumps/emnist/classifier.pth.tar\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] log_file=/data/adv_geom/dumps/emnist/classifier.log\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] training_file=/data/adv_geom/dumps/emnist/training.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] testing_file=/data/adv_geom/dumps/emnist/testing.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] loss_file=/data/adv_geom/dumps/emnist/loss.png\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] error_file=/data/adv_geom/dumps/emnist/error.png\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] gradient_file=/data/adv_geom/dumps/emnist/gradient.png\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] label_index=0\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] training_samples=160000\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] validation_samples=40000\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] test_samples=-1\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] early_stopping=False\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] random_samples=True\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] batch_size=64\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] epochs=10\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] weight_decay=0.0001\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] logit_decay=0\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] use_gpu=True\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] skip=5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] lr=0.01\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] lr_decay=0.95\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] results_file=\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] debug_directory=\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] gpu_id=1\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] network_architecture=mlp\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] network_activation=relu\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] network_no_batch_normalization=False\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] network_channels=16\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] network_dropout=False\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] network_units=1024,1024,1024,1024\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "args = {\n",
    "    \"train_images_file\": \"/data/adv_geom/datasets/emnist/train_images.h5\",\n",
    "    \"train_codes_file\": \"/data/adv_geom/datasets/emnist/train_labels.h5\",\n",
    "    \"test_images_file\": \"/data/adv_geom/datasets/emnist/test_images.h5\",\n",
    "    \"test_codes_file\": \"/data/adv_geom/datasets/emnist/test_labels.h5\",\n",
    "    \"state_file\": \"/data/adv_geom/dumps/emnist/classifier.pth.tar\",\n",
    "    \"label_index\": 0,\n",
    "    \"lr_decay\": 0.95,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"training_samples\": 160000,\n",
    "    \"validation_samples\": 40000,\n",
    "    \"random_samples\": True,\n",
    "    \"network_architecture\": \"mlp\",\n",
    "    \"gpu_id\": 1\n",
    "}\n",
    "\n",
    "sys.argv = [\"-\" + i + \"=\" + str(args[i]) if type(args[i]) != type(True) else \"-\" + i for i in args]\n",
    "\n",
    "\n",
    "program = TrainClassifier(args=sys.argv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py:151: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
      "\u001b[94m[1802210728] [Training] read /data/adv_geom/datasets/emnist/train_images.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] read /data/adv_geom/datasets/emnist/test_images.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] resolution 28\u001b[0m\n",
      "\u001b[94m[1802210728] 240000\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] read /data/adv_geom/datasets/emnist/train_labels.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] read /data/adv_geom/datasets/emnist/test_labels.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] using 160000 training samples\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] found 10 classes\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 0 should have 16000 samples but has 15995\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 1 should have 16000 samples but has 16069\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 2 should have 16000 samples but has 16039\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 3 should have 16000 samples but has 15919\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 4 should have 16000 samples but has 15976\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 5 should have 16000 samples but has 16028\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 6 should have 16000 samples but has 16076\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 7 should have 16000 samples but has 16027\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 8 should have 16000 samples but has 15933\u001b[0m\n",
      "\u001b[93m[1802210728] [Training] dataset not balanced, class 9 should have 16000 samples but has 15938\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "program.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m[1802210728] [Training] using 1 input channels\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] loaded /data/adv_geom/dumps/emnist/classifier.pth.tar\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] model is not CUDA\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] loaded model\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] read /data/adv_geom/dumps/emnist/training.h5\u001b[0m\n",
      "\u001b[94m[1802210728] [Training] read /data/adv_geom/dumps/emnist/testing.h5\u001b[0m\n",
      "\u001b[94m[1802210728] (view0, View)\n",
      "(lin1, Linear)\n",
      "(act1, ReLU)\n",
      "(bn1, BatchNorm1d)\n",
      "(lin2, Linear)\n",
      "(act2, ReLU)\n",
      "(bn2, BatchNorm1d)\n",
      "(lin3, Linear)\n",
      "(act3, ReLU)\n",
      "(bn3, BatchNorm1d)\n",
      "(lin4, Linear)\n",
      "(act4, ReLU)\n",
      "(bn4, BatchNorm1d)\n",
      "(logits, Linear)\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "program.load_model_and_scheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = program.test_images[0:8]\n",
    "test_codes = program.test_codes[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    program.model.cuda()\n",
    "    program.model.eval()\n",
    "    test_image = torch.Tensor(test_image).cuda()\n",
    "    logits = program.model(test_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 9, 7, 9, 2, 2, 3, 1], device='cuda:1')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(logits, axis=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 9, 7, 9, 2, 2, 3, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m[1802210728] [Training] 21 set classifier to eval\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "\u001b[94m[1802210728] [Training] 21: test 0.0860147 (0.0253)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "clf_report = program.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype <U8 cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c6f48e7669e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2731\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    701\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    702\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 703\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype <U8 cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMbElEQVR4nO3bcYikd33H8ffHXFOpjbGYFeTuNJFeqldbMF1Si1BTTMslhbs/LHIHobUED62RglJIsaQS/7JSC8K19kpDVDDx9I+y4EmgNiEQPM2GaPQuRNbTNhelOTXNP8HE0G//mEk72e/uzZO72Znb+n7BwjzP/Hbmu8PwvmeeeS5VhSRNetmiB5B08TEMkhrDIKkxDJIawyCpMQySmqlhSHJHkieTfHuT+5Pkk0nWkjyS5JrZjylpnoYcMdwJ7DvH/TcAe8Y/h4F/uPCxJC3S1DBU1f3AT86x5ADwmRo5AbwqyWtnNaCk+dsxg8fYCTw+sX1mvO+H6xcmOczoqIJXvOIVv/XGN75xBk8vaTMPPfTQj6pq6aX+3izCMFhVHQWOAiwvL9fq6uo8n176uZPk38/n92bxrcQTwO6J7V3jfZK2qVmEYQX44/G3E28Fnq6q9jFC0vYx9aNEkruA64ArkpwB/hr4BYCq+hRwHLgRWAOeAf50q4aVNB9Tw1BVh6bcX8D7ZzaRpIXzykdJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBknNoDAk2ZfksSRrSW7d4P7XJbk3ycNJHkly4+xHlTQvU8OQ5BLgCHADsBc4lGTvumV/BRyrqrcAB4G/n/WgkuZnyBHDtcBaVZ2uqueAu4ED69YU8Mrx7cuBH8xuREnzNiQMO4HHJ7bPjPdN+ghwU5IzwHHgAxs9UJLDSVaTrJ49e/Y8xpU0D7M6+XgIuLOqdgE3Ap9N0h67qo5W1XJVLS8tLc3oqSXN2pAwPAHsntjeNd436WbgGEBVfRV4OXDFLAaUNH9DwvAgsCfJVUkuZXRycWXdmv8A3gGQ5E2MwuBnBWmbmhqGqnoeuAW4B3iU0bcPJ5PcnmT/eNmHgPck+SZwF/DuqqqtGlrS1toxZFFVHWd0UnFy320Tt08Bb5vtaJIWxSsfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSMygMSfYleSzJWpJbN1nzriSnkpxM8rnZjilpnnZMW5DkEuAI8PvAGeDBJCtVdWpizR7gL4G3VdVTSV6zVQNL2npDjhiuBdaq6nRVPQfcDRxYt+Y9wJGqegqgqp6c7ZiS5mlIGHYCj09snxnvm3Q1cHWSB5KcSLJvowdKcjjJapLVs2fPnt/EkrbcrE4+7gD2ANcBh4B/SvKq9Yuq6mhVLVfV8tLS0oyeWtKsDQnDE8Duie1d432TzgArVfWzqvoe8B1GoZC0DQ0Jw4PAniRXJbkUOAisrFvzL4yOFkhyBaOPFqdnN6akeZoahqp6HrgFuAd4FDhWVSeT3J5k/3jZPcCPk5wC7gX+oqp+vFVDS9paqaqFPPHy8nKtrq4u5LmlnxdJHqqq5Zf6e175KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyWZC3JredY984klWR5diNKmrepYUhyCXAEuAHYCxxKsneDdZcBfw58bdZDSpqvIUcM1wJrVXW6qp4D7gYObLDuo8DHgJ/OcD5JCzAkDDuBxye2z4z3/a8k1wC7q+pL53qgJIeTrCZZPXv27EseVtJ8XPDJxyQvAz4BfGja2qo6WlXLVbW8tLR0oU8taYsMCcMTwO6J7V3jfS+4DHgzcF+S7wNvBVY8ASltX0PC8CCwJ8lVSS4FDgIrL9xZVU9X1RVVdWVVXQmcAPZX1eqWTCxpy00NQ1U9D9wC3AM8ChyrqpNJbk+yf6sHlDR/O4YsqqrjwPF1+27bZO11Fz6WpEXyykdJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQMCkOSfUkeS7KW5NYN7v9gklNJHknylSSvn/2okuZlahiSXAIcAW4A9gKHkuxdt+xhYLmqfhP4IvA3sx5U0vwMOWK4FlirqtNV9RxwN3BgckFV3VtVz4w3TwC7ZjumpHkaEoadwOMT22fG+zZzM/Dlje5IcjjJapLVs2fPDp9S0lzN9ORjkpuAZeDjG91fVUerarmqlpeWlmb51JJmaMeANU8Auye2d433vUiS64EPA2+vqmdnM56kRRhyxPAgsCfJVUkuBQ4CK5MLkrwF+Edgf1U9OfsxJc3T1DBU1fPALcA9wKPAsao6meT2JPvHyz4O/DLwhSTfSLKyycNJ2gaGfJSgqo4Dx9ftu23i9vUznkvSAnnlo6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpGZQGJLsS/JYkrUkt25w/y8m+fz4/q8luXLmk0qam6lhSHIJcAS4AdgLHEqyd92ym4GnqupXgb8DPjbrQSXNz5AjhmuBtao6XVXPAXcDB9atOQB8enz7i8A7kmR2Y0qapx0D1uwEHp/YPgP89mZrqur5JE8DrwZ+NLkoyWHg8Hjz2STfPp+hF+QK1v09F7HtNCtsr3m306wAv3Y+vzQkDDNTVUeBowBJVqtqeZ7PfyG207zbaVbYXvNup1lhNO/5/N6QjxJPALsntneN9224JskO4HLgx+czkKTFGxKGB4E9Sa5KcilwEFhZt2YF+JPx7T8C/q2qanZjSpqnqR8lxucMbgHuAS4B7qiqk0luB1aragX4Z+CzSdaAnzCKxzRHL2DuRdhO826nWWF7zbudZoXznDf+wy5pPa98lNQYBknNlodhO11OPWDWDyY5leSRJF9J8vpFzDkxzznnnVj3ziSVZGFfsw2ZNcm7xq/vySSfm/eM62aZ9l54XZJ7kzw8fj/cuIg5x7PckeTJza4Lysgnx3/LI0mumfqgVbVlP4xOVn4XeANwKfBNYO+6NX8GfGp8+yDw+a2c6QJn/T3gl8a337eoWYfOO153GXA/cAJYvlhnBfYADwO/Mt5+zcX82jI6qfe+8e29wPcXOO/vAtcA397k/huBLwMB3gp8bdpjbvURw3a6nHrqrFV1b1U9M948weiajkUZ8toCfJTR/1356TyHW2fIrO8BjlTVUwBV9eScZ5w0ZN4CXjm+fTnwgznO9+JBqu5n9G3gZg4An6mRE8Crkrz2XI+51WHY6HLqnZutqarngRcup563IbNOuplRhRdl6rzjQ8bdVfWleQ62gSGv7dXA1UkeSHIiyb65TdcNmfcjwE1JzgDHgQ/MZ7Tz8lLf2/O9JPr/iyQ3AcvA2xc9y2aSvAz4BPDuBY8y1A5GHyeuY3Qkdn+S36iq/1rkUOdwCLizqv42ye8wuo7nzVX134sebBa2+ohhO11OPWRWklwPfBjYX1XPzmm2jUyb9zLgzcB9Sb7P6LPlyoJOQA55bc8AK1X1s6r6HvAdRqFYhCHz3gwcA6iqrwIvZ/QfrC5Gg97bL7LFJ0V2AKeBq/i/kzi/vm7N+3nxycdjCzqBM2TWtzA6KbVnETO+1HnXrb+PxZ18HPLa7gM+Pb59BaND31dfxPN+GXj3+PabGJ1jyALfD1ey+cnHP+TFJx+/PvXx5jDwjYzq/13gw+N9tzP6FxdGpf0CsAZ8HXjDAl/cabP+K/CfwDfGPyuLmnXIvOvWLiwMA1/bMProcwr4FnDwYn5tGX0T8cA4Gt8A/mCBs94F/BD4GaMjr5uB9wLvnXhtj4z/lm8NeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdVj8DQ4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (view0): View()\n",
       "  (lin1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (act2): ReLU(inplace=True)\n",
       "  (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (act3): ReLU(inplace=True)\n",
       "  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (act4): ReLU(inplace=True)\n",
       "  (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logits): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9626394953905871, 'recall': 0.992, 'f1-score': 0.9770992366412214, 'support': 4000}, '1': {'precision': 0.9904690243290695, 'recall': 0.98725, 'f1-score': 0.9888568924502316, 'support': 4000}, '2': {'precision': 0.9852941176470589, 'recall': 0.9715, 'f1-score': 0.9783484390735147, 'support': 4000}, '3': {'precision': 0.9777384265115102, 'recall': 0.96625, 'f1-score': 0.9719602665660757, 'support': 4000}, '4': {'precision': 0.9449081803005008, 'recall': 0.9905, 'f1-score': 0.9671670938606127, 'support': 4000}, '5': {'precision': 0.9778393351800554, 'recall': 0.97075, 'f1-score': 0.9742817714214026, 'support': 4000}, '6': {'precision': 0.9911144960649911, 'recall': 0.976, 'f1-score': 0.9834991812570852, 'support': 4000}, '7': {'precision': 0.9646255184191266, 'recall': 0.9885, 'f1-score': 0.9764168415853809, 'support': 4000}, '8': {'precision': 0.9805277991288752, 'recall': 0.95675, 'f1-score': 0.9684929773503733, 'support': 4000}, '9': {'precision': 0.9745435844690151, 'recall': 0.9475, 'f1-score': 0.9608315375839777, 'support': 4000}, 'accuracy': 0.9747, 'macro avg': {'precision': 0.9749699977440791, 'recall': 0.9747, 'f1-score': 0.9746954237789875, 'support': 40000}, 'weighted avg': {'precision': 0.9749699977440789, 'recall': 0.9747, 'f1-score': 0.9746954237789877, 'support': 40000}}\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_basis = np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = leftover_basis.copy()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals = np.zeros((10, 5)) + 2 * leftover_basis[0] + 3 * leftover_basis[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  3.        ,  0.93005725, -2.7010941 , -0.09077931],\n",
       "       [ 2.        ,  3.        , -0.69655886,  0.26599289, -0.63374743],\n",
       "       [ 2.        ,  3.        ,  0.95881895,  0.69475701, -0.20281078],\n",
       "       [ 2.        ,  3.        ,  1.28920211, -1.43408625,  0.94957857],\n",
       "       [ 2.        ,  3.        , -0.67751683,  0.05920811,  1.6907731 ],\n",
       "       [ 2.        ,  3.        , -0.56870177, -0.61534187,  0.26821735],\n",
       "       [ 2.        ,  3.        , -1.27474265, -0.64271102,  0.08352661],\n",
       "       [ 2.        ,  3.        ,  1.24514789,  0.66912761, -0.47381287],\n",
       "       [ 2.        ,  3.        , -1.28627607,  0.9567944 ,  0.32609812],\n",
       "       [ 2.        ,  3.        ,  0.90049908, -1.8664123 ,  0.42058855]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normals + np.random.normal(size=(10, 5)) * np.sum(span, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).reshape(-1, 1)\n",
    "b = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/azuredrive/dumps/expC_dist_learner_for_adv_ex/dist_learner/test_MLPwithNormalization_model{hidden_sizes=512x4,sigmoid_last,batch_norm}_data{2spheres_in_unit_cube;n=100;k=2}/31052021-192633/models\n",
      "/azuredrive/dumps/expC_dist_learner_for_adv_ex/dist_learner/test_MLPwithNormalization_model{hidden_sizes=512x4,sigmoid_last,batch_norm}_data{2spheres_in_unit_cube;n=100;k=2}/31052021-192633/models\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dump_dir = \"/azuredrive/dumps/expC_dist_learner_for_adv_ex/dist_learner/test_MLPwithNormalization_model{hidden_sizes=512x4,sigmoid_last,batch_norm}_data{2spheres_in_unit_cube;n=100;k=2}/\"\n",
    "os.chdir(dump_dir)\n",
    "x = None\n",
    "for root, dirs, files in os.walk(dump_dir):\n",
    "    if \"models\" in root and len(files) > 1:\n",
    "        x = files\n",
    "        print(root)\n",
    "        best_model_fn = sorted(x, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))[-1]\n",
    "        \n",
    "        if len(x) > 1:\n",
    "            for j in x:\n",
    "                if j != best_model_fn:\n",
    "                    os.remove(os.path.join(root, j))\n",
    "            print(root)\n",
    "            \n",
    "        \n",
    "#         for file in files:\n",
    "#             if file.endswith(\".pth\"):\n",
    "#                  print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'test_MLPwithNormalization_model{hidden_sizes=512x4,sigmoid_last,batch_norm}_data{2spheres_in_unit_cube;n=100;k=2}_31052021-192633_val_loss_9.026023826663732e-06_epoch_499.pth'\r\n"
     ]
    }
   ],
   "source": [
    "! ls \"/azuredrive/dumps/expC_dist_learner_for_adv_ex/dist_learner/test_MLPwithNormalization_model{hidden_sizes=512x4,sigmoid_last,batch_norm}_data{2spheres_in_unit_cube;n=100;k=2}/31052021-192633/models\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = [\"train\", \"val\", \"test\"]\n",
    "# data_fns = [TRAIN_FN, VAL_FN, TEST_FN]\n",
    "\n",
    "splits = {i[0]: {\"fn\": i[1], \"name\": i[0]} for i in zip(phases, phases)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'fn': 'train', 'name': 'train'},\n",
       " 'val': {'fn': 'val', 'name': 'val'},\n",
       " 'test': {'fn': 'test', 'name': 'test'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
